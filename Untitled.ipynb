{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OMIGIEO\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<firebase_admin.App at 0x22be4927630>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import firebase_admin\n",
    "import pandas as pd\n",
    "from firebase_admin import credentials, db\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import time\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "WAIT_DURATION = 2\n",
    "cred = credentials.Certificate('myawesomeinsole-firebase-adminsdk.json')\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL' : 'https://myawesomeinsole.firebaseio.com'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OMIGIEO\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3405: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# feature extraction\n",
    "def get_mean(l, col):\n",
    "    \"\"\"mean of accelerometer data\"\"\"\n",
    "    return np.mean(l[col])\n",
    "\n",
    "def get_median(l, col):\n",
    "    \"\"\"median of accelerometer data\"\"\"\n",
    "    return np.median(l[col])\n",
    "\n",
    "\n",
    "def get_mode(l, col):\n",
    "    \"\"\"Mode of accelerometer data\"\"\"\n",
    "    return stats.mode(l[col])[0][0]\n",
    "\n",
    "def no_of_events(l,col):\n",
    "    \"\"\"number of times a touchdown event occured\"\"\"\n",
    "    count = 0\n",
    "    for item in l[col]:\n",
    "        if not np.isnan(item):\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def no_of_true_events(l,col):\n",
    "    \"\"\"number of times the sensor has a true value\"\"\"\n",
    "    count = 0\n",
    "    for item in l[col]:\n",
    "        if not np.isnan(item):\n",
    "            if(item):\n",
    "                count+=1\n",
    "    return count\n",
    "\n",
    "def duration_between_consecutive_events(l,col):\n",
    "    prev_timestamp = 0\n",
    "    current_timestamp = 0\n",
    "    difference = []\n",
    "    \"\"\"time duration between two steps of \"\"\"\n",
    "    for index,item in enumerate(l[col]):\n",
    "        if not np.isnan(item):\n",
    "            if(item):\n",
    "                current_timestamp = l['timestamp'].iloc[index]\n",
    "                difference.append(current_timestamp-prev_timestamp)\n",
    "                prev_timestamp = current_timestamp\n",
    "                \n",
    "    if(difference):\n",
    "        difference.pop(0)\n",
    "        return difference\n",
    "    else:\n",
    "        return float('nan')\n",
    "    \n",
    "def get_Time_difference_mean(l):\n",
    "    \"\"\"mean of time difference between two consecutive steps\"\"\"\n",
    "    return np.mean(l)\n",
    "\n",
    "def get_Time_difference_median(l):\n",
    "    \"\"\"median of time difference between two consecutive steps\"\"\"\n",
    "    return np.nanmedian(l)\n",
    "\n",
    "def feature_extraction(data_df):\n",
    "    feature_df = pd.DataFrame(columns = ['Mean_Ax','Mode_Ax', 'Median_Ax', 'Mean_Ay','Mode_Ay','Median_Ay','Mean_Az','Mode_Az','Median_Az',\n",
    "                                         'Mean_Bx','Mode_Bx', 'Median_Bx', 'Mean_By','Mode_By','Median_By','Mean_Bz','Mode_Bz','Median_Bz',\n",
    "                                         'Mean_Cx','Mode_Cx', 'Median_Cx', 'Mean_Cy','Mode_Cy','Median_Cy','Mean_Cz','Mode_Cz','Median_Cz',\n",
    "                                         'no_of_events_occured','no_of_True_events_occured_A','no_of_True_events_occured_B',\n",
    "                                         'no_of_True_events_occured_C','no_of_True_events_occured_D',\n",
    "                                         'Mean_impact','Mode_impact','Median_impact','Time_difference_mean_A','Time_difference_median_A', 'Time_difference_mean_B','Time_difference_median_B',\n",
    "                                        'Time_difference_mean_C','Time_difference_median_C', 'Time_difference_mean_D','Time_difference_median_D'])\n",
    "\n",
    "    td_mn_A = get_Time_difference_mean(duration_between_consecutive_events(data_df,'A'))\n",
    "    td_mn_B = get_Time_difference_mean(duration_between_consecutive_events(data_df,'B'))\n",
    "    td_mn_C = get_Time_difference_mean(duration_between_consecutive_events(data_df,'C'))\n",
    "    td_mn_D = get_Time_difference_mean(duration_between_consecutive_events(data_df,'D'))\n",
    "    td_md_A = get_Time_difference_median(duration_between_consecutive_events(data_df,'A'))\n",
    "    td_md_B = get_Time_difference_median(duration_between_consecutive_events(data_df,'B'))\n",
    "    td_md_C = get_Time_difference_median(duration_between_consecutive_events(data_df,'C'))\n",
    "    td_md_D = get_Time_difference_median(duration_between_consecutive_events(data_df,'D'))\n",
    "\n",
    "    feature_df = feature_df.append({'Mean_Ax':get_mean(data_df ,'Ax'),'Mode_Ax':get_mode(data_df ,'Ax'),'Median_Ax':get_median(data_df,'Ax'),\n",
    "                                    'Mean_Ay':get_mean(data_df ,'Ay'),'Mode_Ay':get_mode(data_df ,'Ay'),'Median_Ay':get_median(data_df ,'Ay'),\n",
    "                                    'Mean_Az':get_mean(data_df ,'Az'),'Mode_Az':get_mode(data_df ,'Az'),'Median_Az':get_median(data_df ,'Az'),\n",
    "                                    'Mean_Bx':get_mean(data_df ,'Bx'),'Mode_Bx':get_mode(data_df ,'Bx'),'Median_Bx':get_median(data_df ,'Bx'), \n",
    "                                    'Mean_By':get_mean(data_df ,'By'),'Mode_By':get_mode(data_df ,'By'),'Median_By':get_median(data_df ,'By'),\n",
    "                                    'Mean_Bz':get_mean(data_df ,'Bz'),'Mode_Bz':get_mean(data_df ,'Bz'),'Median_Bz':get_median(data_df ,'Bz'),\n",
    "                                    'Mean_Cx':get_mean(data_df ,'Cx'),'Mode_Cx':get_mode(data_df ,'Cx'),'Median_Cx':get_median(data_df ,'Cx'),\n",
    "                                    'Mean_Cy':get_mean(data_df ,'Cy'),'Mode_Cy':get_mode(data_df ,'Cy'),'Median_Cy':get_median(data_df ,'Cy'),\n",
    "                                    'Mean_Cz':get_mean(data_df ,'Cz'),'Mode_Cz':get_mode(data_df ,'Cz'),'Median_Cz':get_median(data_df ,'Cz'),\n",
    "                                    'no_of_events_occured':no_of_events(data_df ,'A'),\n",
    "                                    'no_of_True_events_occured_A':no_of_true_events(data_df ,'A'),\n",
    "                                    'no_of_True_events_occured_B':no_of_true_events(data_df ,'B'),\n",
    "                                    'no_of_True_events_occured_C':no_of_true_events(data_df ,'C'),\n",
    "                                    'no_of_True_events_occured_D':no_of_true_events(data_df ,'D'),\n",
    "                                    'Mean_impact':get_mean(data_df ,'impact'),'Mode_impact':get_mode(data_df ,'impact'),'Median_impact':get_median(data_df ,'impact'),\n",
    "                                    'Time_difference_mean_A':td_mn_A,'Time_difference_median_A':td_md_A, \n",
    "                                    'Time_difference_mean_B':td_mn_B,'Time_difference_median_B':td_md_B,\n",
    "                                    'Time_difference_mean_C':td_mn_C,'Time_difference_median_C':td_md_C, \n",
    "                                    'Time_difference_mean_D':td_mn_D,'Time_difference_median_D':td_md_D},ignore_index=True)\n",
    "    return feature_df\n",
    "\n",
    "def transpose_data(data):\n",
    "    data = pd.DataFrame(data).T\n",
    "    data = data.reset_index(level=0).rename(columns = {'index' : 'timestamp'})\n",
    "    data['timestamp'].astype('int64')\n",
    "    data = data.sort_values('timestamp', ascending=False)\n",
    "    return data \n",
    "\n",
    "def clean_data(data):\n",
    "    accelerometer_data = transpose_data(data['AccelerometerData'])\n",
    "    if 'SensorReading' in data:\n",
    "        sensor_data = transpose_data(data['SensorReading'])\n",
    "    else:\n",
    "        sensor_data = pd.DataFrame(columns=['timestamp','A','B','C','D','forefoot','heel','impact','varus','sole'])\n",
    "    sensor_data[['A','B','C','D']]*= 1\n",
    "    sensor_data = pd.merge(accelerometer_data, sensor_data, how='outer', on=['timestamp', 'timestamp'])\n",
    "    sensor_data = sensor_data.drop(['forefoot', 'heel','sole','varus' ], axis=1)\n",
    "    sensor_data = sensor_data.reset_index(drop=True).rename(columns={'index':'timestamp'})\n",
    "    return sensor_data\n",
    "\n",
    "\n",
    "\n",
    "data = db.reference(f'Data/{left_sole}').get()\n",
    "data_df = clean_data(data)\n",
    "feature_df = feature_extraction(data_df)\n",
    "feature_df = feature_df.fillna(-1000)\n",
    "print(activities_mapping[model.predict(feature_df)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OMIGIEO\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\sklearn\\base.py:306: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\OMIGIEO\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3405: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OMIGIEO\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3405: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OMIGIEO\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3405: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OMIGIEO\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3405: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OMIGIEO\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3405: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OMIGIEO\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3405: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sitting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def change_event_handler(event):\n",
    "    while True:\n",
    "        time.sleep(WAIT_DURATION)\n",
    "        data = db.reference(f'Data/{left_sole}').get()\n",
    "        if data:\n",
    "            data_df = clean_data(data)\n",
    "            feature_df = feature_extraction(data_df)\n",
    "            feature_df = feature_df.fillna(-1000)\n",
    "            print(activities_mapping[model.predict(feature_df)[0]])\n",
    "#             save_result()\n",
    "#             delete_data()\n",
    "        else:\n",
    "            break \n",
    "\n",
    "activities_mapping = {1:'walking', 2:'running', 3:'sitting', 4:'standing', 5:'stairup', 6:'stairdown', 7:'elliptical'}\n",
    "with open(r\"saved_decision_tree_model_latest.pkl\", \"rb\") as input_file:\n",
    "    model = joblib.load(input_file)\n",
    "                             \n",
    "left_sole = db.reference('Insole/Left/DeviceName').get()\n",
    "root = db.reference().listen(change_event_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import firebase_admin\n",
    "import pandas as pd\n",
    "from firebase_admin import credentials, db\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import time\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# feature extraction\n",
    "def get_mean(l, col):\n",
    "    \"\"\"mean of accelerometer data\"\"\"\n",
    "    return np.mean(l[col])\n",
    "\n",
    "def get_median(l, col):\n",
    "    \"\"\"median of accelerometer data\"\"\"\n",
    "    return np.median(l[col])\n",
    "\n",
    "\n",
    "def get_mode(l, col):\n",
    "    \"\"\"Mode of accelerometer data\"\"\"\n",
    "    return stats.mode(l[col])[0][0]\n",
    "\n",
    "def no_of_events(l,col):\n",
    "    \"\"\"number of times a touchdown event occured\"\"\"\n",
    "    count = 0\n",
    "    for item in l[col]:\n",
    "        if not np.isnan(item):\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def no_of_true_events(l,col):\n",
    "    \"\"\"number of times the sensor has a true value\"\"\"\n",
    "    count = 0\n",
    "    for item in l[col]:\n",
    "        if not np.isnan(item):\n",
    "            if(item):\n",
    "                count+=1\n",
    "    return count\n",
    "\n",
    "def duration_between_consecutive_events(l,col):\n",
    "    prev_timestamp = 0\n",
    "    current_timestamp = 0\n",
    "    difference = []\n",
    "    \"\"\"time duration between two steps of \"\"\"\n",
    "    for index,item in enumerate(l[col]):\n",
    "        if not np.isnan(item):\n",
    "            if(item):\n",
    "                current_timestamp = l['timestamp'].iloc[index]\n",
    "                difference.append(current_timestamp-prev_timestamp)\n",
    "                prev_timestamp = current_timestamp\n",
    "                \n",
    "    if(difference):\n",
    "        difference.pop(0)\n",
    "        return difference\n",
    "    else:\n",
    "        return float('nan')\n",
    "    \n",
    "def get_Time_difference_mean(l):\n",
    "    \"\"\"mean of time difference between two consecutive steps\"\"\"\n",
    "    return np.mean(l)\n",
    "\n",
    "def get_Time_difference_median(l):\n",
    "    \"\"\"median of time difference between two consecutive steps\"\"\"\n",
    "    return np.nanmedian(l)\n",
    "\n",
    "def feature_extraction(data_df):\n",
    "    feature_df = pd.DataFrame(columns = ['Mean_Ax','Mode_Ax', 'Median_Ax', 'Mean_Ay','Mode_Ay','Median_Ay','Mean_Az','Mode_Az','Median_Az',\n",
    "                                         'Mean_Bx','Mode_Bx', 'Median_Bx', 'Mean_By','Mode_By','Median_By','Mean_Bz','Mode_Bz','Median_Bz',\n",
    "                                         'Mean_Cx','Mode_Cx', 'Median_Cx', 'Mean_Cy','Mode_Cy','Median_Cy','Mean_Cz','Mode_Cz','Median_Cz',\n",
    "                                         'no_of_events_occured','no_of_True_events_occured_A','no_of_True_events_occured_B',\n",
    "                                         'no_of_True_events_occured_C','no_of_True_events_occured_D',\n",
    "                                         'Mean_impact','Mode_impact','Median_impact','Time_difference_mean_A','Time_difference_median_A', 'Time_difference_mean_B','Time_difference_median_B',\n",
    "                                        'Time_difference_mean_C','Time_difference_median_C', 'Time_difference_mean_D','Time_difference_median_D'])\n",
    "\n",
    "    td_mn_A = get_Time_difference_mean(duration_between_consecutive_events(data_df,'A'))\n",
    "    td_mn_B = get_Time_difference_mean(duration_between_consecutive_events(data_df,'B'))\n",
    "    td_mn_C = get_Time_difference_mean(duration_between_consecutive_events(data_df,'C'))\n",
    "    td_mn_D = get_Time_difference_mean(duration_between_consecutive_events(data_df,'D'))\n",
    "    td_md_A = get_Time_difference_median(duration_between_consecutive_events(data_df,'A'))\n",
    "    td_md_B = get_Time_difference_median(duration_between_consecutive_events(data_df,'B'))\n",
    "    td_md_C = get_Time_difference_median(duration_between_consecutive_events(data_df,'C'))\n",
    "    td_md_D = get_Time_difference_median(duration_between_consecutive_events(data_df,'D'))\n",
    "\n",
    "    feature_df = feature_df.append({'Mean_Ax':get_mean(data_df ,'Ax'),'Mode_Ax':get_mode(data_df ,'Ax'),'Median_Ax':get_median(data_df,'Ax'),\n",
    "                                    'Mean_Ay':get_mean(data_df ,'Ay'),'Mode_Ay':get_mode(data_df ,'Ay'),'Median_Ay':get_median(data_df ,'Ay'),\n",
    "                                    'Mean_Az':get_mean(data_df ,'Az'),'Mode_Az':get_mode(data_df ,'Az'),'Median_Az':get_median(data_df ,'Az'),\n",
    "                                    'Mean_Bx':get_mean(data_df ,'Bx'),'Mode_Bx':get_mode(data_df ,'Bx'),'Median_Bx':get_median(data_df ,'Bx'), \n",
    "                                    'Mean_By':get_mean(data_df ,'By'),'Mode_By':get_mode(data_df ,'By'),'Median_By':get_median(data_df ,'By'),\n",
    "                                    'Mean_Bz':get_mean(data_df ,'Bz'),'Mode_Bz':get_mean(data_df ,'Bz'),'Median_Bz':get_median(data_df ,'Bz'),\n",
    "                                    'Mean_Cx':get_mean(data_df ,'Cx'),'Mode_Cx':get_mode(data_df ,'Cx'),'Median_Cx':get_median(data_df ,'Cx'),\n",
    "                                    'Mean_Cy':get_mean(data_df ,'Cy'),'Mode_Cy':get_mode(data_df ,'Cy'),'Median_Cy':get_median(data_df ,'Cy'),\n",
    "                                    'Mean_Cz':get_mean(data_df ,'Cz'),'Mode_Cz':get_mode(data_df ,'Cz'),'Median_Cz':get_median(data_df ,'Cz'),\n",
    "                                    'no_of_events_occured':no_of_events(data_df ,'A'),\n",
    "                                    'no_of_True_events_occured_A':no_of_true_events(data_df ,'A'),\n",
    "                                    'no_of_True_events_occured_B':no_of_true_events(data_df ,'B'),\n",
    "                                    'no_of_True_events_occured_C':no_of_true_events(data_df ,'C'),\n",
    "                                    'no_of_True_events_occured_D':no_of_true_events(data_df ,'D'),\n",
    "                                    'Mean_impact':get_mean(data_df ,'impact'),'Mode_impact':get_mode(data_df ,'impact'),'Median_impact':get_median(data_df ,'impact'),\n",
    "                                    'Time_difference_mean_A':td_mn_A,'Time_difference_median_A':td_md_A, \n",
    "                                    'Time_difference_mean_B':td_mn_B,'Time_difference_median_B':td_md_B,\n",
    "                                    'Time_difference_mean_C':td_mn_C,'Time_difference_median_C':td_md_C, \n",
    "                                    'Time_difference_mean_D':td_mn_D,'Time_difference_median_D':td_md_D},ignore_index=True)\n",
    "    return feature_df\n",
    "\n",
    "def transpose_data(data):\n",
    "    data = pd.DataFrame(data).T\n",
    "    data = data.reset_index(level=0).rename(columns = {'index' : 'timestamp'})\n",
    "    data['timestamp'].astype('int64')\n",
    "    data = data.sort_values('timestamp', ascending=False)\n",
    "    return data \n",
    " \n",
    "def clean_data(data):\n",
    "    accelerometer_data = transpose_data(data['AccelerometerData'])\n",
    "    if 'SensorReading' in data:\n",
    "        sensor_data = transpose_data(data['SensorReading'])\n",
    "    else:\n",
    "        sensor_data = pd.DataFrame(columns=['timestamp','A','B','C','D','forefoot','heel','impact','varus','sole'])\n",
    "    sensor_data[['A','B','C','D']]*= 1\n",
    "    sensor_data = pd.merge(accelerometer_data, sensor_data, how='outer', on=['timestamp', 'timestamp'])\n",
    "    sensor_data = sensor_data.drop(['forefoot', 'heel','sole','varus' ], axis=1)\n",
    "    sensor_data = sensor_data.reset_index(drop=True).rename(columns={'index':'timestamp'})\n",
    "    return sensor_data\n",
    "\n",
    "def change_event_handler(event):\n",
    "    while True:\n",
    "        time.sleep(WAIT_DURATION)\n",
    "        data = db.reference(f'Data/{left_sole}').get()\n",
    "        if data:\n",
    "            data_df = clean_data(data)\n",
    "            feature_df = feature_extraction(data_df)\n",
    "            feature_df = feature_df.fillna(-1000)\n",
    "            print(EVENT_MAPPING[model.predict(feature_df)[0]])\n",
    "#             save_result()\n",
    "#             delete_data()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    WAIT_DURATION = 2\n",
    "    EVENT_MAPPING = {1:'walking', 2:'running', 3:'sitting', 4:'standing', 5:'stairup', 6:'stairdown', 7:'elliptical'}\n",
    "    with open(r\"saved_decision_tree_model_latest.pkl\", \"rb\") as input_file:\n",
    "        model = joblib.load(input_file)\n",
    "\n",
    "    cred = credentials.Certificate('myawesomeinsole-firebase-adminsdk.json')\n",
    "    firebase_admin.initialize_app(cred, {\n",
    "        'databaseURL' : 'https://myawesomeinsole.firebaseio.com'\n",
    "    })           \n",
    "    left_sole = db.reference('Insole/Left/DeviceName').get()\n",
    "    root = db.reference().listen(change_event_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
